{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What exactly is a feature? Give an example to illustrate your point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: A feature is an attribute of a data set that is used in machine learning process. Example of feature can be Years of experience and degree for predicting salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What are the various circumstances in which feature construction is required?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: The cirumstances where the accuracy or any other metrics we chossed for are model is not making progress in such situation it becomes important to contruct new meaningful features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Describe how nominal variables are encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: In order to encode nominal data, first we need to figure out which feature is having nominal values by choosing object data type. For example a feature with two values like Male and Feamle can be encoded as 1 for Male and 0 for Female. Other kind of approaches like replace it with their count values can also be used. We can also use label encoding or one hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Describe how numeric features are converted to categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: One of the most useful ways for converting numeric feature to categorical is by binning. Suppose we encode values which falls within 1 to 10 as 1, 11 to 20 as 2 and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Describe the feature selection wrapper approach. State the advantages and disadvantages of this approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Now a days we have data set with lots of feature which increased the importance like never before. The wraper method, evaluates the machine learning algorithm to find optimal feature. This method is high on computation for large data set. There are high chances of over-fitting. Example of this method are forward selection, backward elemination and step-wise selection. The wraper method uses greedy approach by evaluating all feature combination on given criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. When is a feature considered irrelevant? What can be said to quantify it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Feature is said to be irrelevant when it does not help the model in predicting target variable. Such features are better off dropped because they are noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. When is a function considered redundant? What criteria are used to identify features that could be redundant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: What are the redundant features in machine learning? Redundant features add no relevant information to your other features, because they are correlated or because they can be obtained by [linear] combination of other features. Having them on your set will not add anything, but it won't hurt either, information-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. What are the various distance measurements used to determine feature similarity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Similarity measures are used to understand how similar two data are to eachother. 5 similarity measures are, Euclidean distance, Manhattan distance, Minkowski distance,Cosine Similarity, Jaccard Similarity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. State difference between Euclidean and Manhattan distances?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Euclidean distance is simple distance as it is distance of lenght of part connecting them- Manhattan distance is the total sum of the difference between the x-coordinates and y-coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import*\n",
    "\n",
    "def euclidean_distance(x,y):\n",
    " \n",
    "    return sqrt(sum(pow(a-b,2) for a, b in zip(x, y)))\n",
    " \n",
    "def manhattan_distance(x,y):\n",
    " \n",
    "    return sum(abs(a-b) for a,b in zip(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Distinguish between feature transformation and feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Feature transformation is transofrmation of data to increase the evaluation metrics result - Feature selection is removal of unnecessary feature.\n",
    "\n",
    "Feature transofrmation includes scaling of feature using StandardScalar or MinMaxScaler or np.log transformation for dealing with large values- Some of availabel Feature selection options are Variance Threshold, SelectKBest,SelectFromModel, SequentialFeatureSelector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Make brief notes on any two of the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      1.SVD (Standard Variable Diameter Diameter)\n",
    "\n",
    "      Ans: SVD is a technique from linear algebra that can be used to automatically perform dimensionality reduction. SVD can be thought of as a projection method where data with m-columns (features) is projected into a subspace with m or fewer columns, whilst retaining the essence of the original data.\n",
    "\n",
    "The SVD is used widely both in the calculation of other matrix operations, such as matrix inverse, but also as a data reduction method in machine learning. Application example of SVD: Recommender system, movie rating prediction. etc\n",
    "\n",
    "      2. Collection of features using a hybrid approach\n",
    "\n",
    "      3. The width of the silhouette\n",
    "\n",
    "      4. Receiver operating characteristic curve\n",
    "Ans: ROC Curve is used as evaluation for classification. It shows the trade off between Sensitivity and Specificity. In a ROC curve, a higher X-axis value indicates a higher number of False positives than True negatives. While a higher Y-axis value indicates a higher number of True positives than False negatives. It plots False positive rate vs True positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
